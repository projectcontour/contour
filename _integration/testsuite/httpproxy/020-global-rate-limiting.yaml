# Copyright Project Contour Authors
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may
# not use this file except in compliance with the License.  You may obtain
# a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
# License for the specific language governing permissions and limitations
# under the License.

# This check depends on the `--watch=endpoints` argument being given
# to integration-tester.

---

apiVersion: apps/v1
kind: Deployment
metadata:
  name: ingress-conformance-echo
$apply:
  fixture:
    as: echo

---

apiVersion: v1
kind: Service
metadata:
  name: ingress-conformance-echo
$apply:
  fixture:
    as: echo

---

# Create the HTTPProxy without rate limits first
# and wait until we get a 200 from it before applying
# rate limits and counting responses. This ensures
# the pods are up and receiving traffic and prevents
# the test from being flaky.

apiVersion: projectcontour.io/v1
kind: HTTPProxy
metadata:
  name: vhostratelimit
spec:
  virtualhost:
    fqdn: vhostratelimit.projectcontour.io
  routes:
  - services:
    - name: echo
      port: 80
---

# Wait until we get a 200 from the proxy confirming
# the pods are up and serving traffic.

import data.contour.http.client
import data.contour.http.client.url
import data.contour.http.expect

Response := client.Get({
  "url": url.http("/"),
  "headers": {
    "Host": "vhostratelimit.projectcontour.io",
    "User-Agent": client.ua("global-rate-limit"),
  },
})

check_for_status_code [msg] {
  msg := expect.response_status_is(Response, 200)
}

---


# Add a global rate limit policy on the virtual host.

apiVersion: projectcontour.io/v1
kind: HTTPProxy
metadata:
  name: vhostratelimit
spec:
  virtualhost:
    fqdn: vhostratelimit.projectcontour.io
    rateLimitPolicy:
      global:
        descriptors:
          - entries:
              - genericKey:
                  value: vhostlimit
  routes:
  - services:
    - name: echo
      port: 80
---

# Make a request against the proxy, confirm a 200 response
# is returned since we're allowed one request per hour.

import data.contour.http.client
import data.contour.http.client.url
import data.contour.http.expect

Response := client.Get({
  "url": url.http("/"),
  "headers": {
    "Host": "vhostratelimit.projectcontour.io",
    "User-Agent": client.ua("global-rate-limit"),
  },
})

check_for_status_code [msg] {
  msg := expect.response_status_is(Response, 200)
}

---

# Make another request against the proxy, confirm a 429
# response is now gotten since we've exceeded the rate
# limit.

import data.contour.http.client
import data.contour.http.client.url
import data.contour.http.expect

Response := client.Get({
  "url": url.http("/"),
  "headers": {
    "Host": "vhostratelimit.projectcontour.io",
    "User-Agent": client.ua("global-rate-limit"),
  },
})

check_for_status_code [msg] {
  msg := expect.response_status_is(Response, 429)
}

---

# This proxy has a global rate limit on a route.
apiVersion: projectcontour.io/v1
kind: HTTPProxy
metadata:
  name: routeratelimit
spec:
  virtualhost:
    fqdn: routeratelimit.projectcontour.io
  routes:
  - services:
    - name: echo
      port: 80
    rateLimitPolicy:
      global:
        descriptors:
          - entries:
              - genericKey:
                  value: routelimit
  - conditions:
      - prefix: /unlimited
    services:
    - name: echo
      port: 80
---

# Make a request against the proxy, confirm a 200 response
# is returned since we're allowed one request per hour.

import data.contour.http.client
import data.contour.http.client.url
import data.contour.http.expect

Response := client.Get({
  "url": url.http("/"),
  "headers": {
    "Host": "routeratelimit.projectcontour.io",
    "User-Agent": client.ua("global-rate-limit"),
  },
})

check_for_status_code [msg] {
  msg := expect.response_status_is(Response, 200)
}

---

# Make another request against the proxy, confirm a 429
# response is now gotten since we've exceeded the rate
# limit.

import data.contour.http.client
import data.contour.http.client.url
import data.contour.http.expect

Response := client.Get({
  "url": url.http("/"),
  "headers": {
    "Host": "routeratelimit.projectcontour.io",
    "User-Agent": client.ua("global-rate-limit"),
  },
})

check_for_status_code [msg] {
  msg := expect.response_status_is(Response, 429)
}

---

# Make a request against the route that doesn't have
# rate limiting to confirm we still get a 200 for that
# route.

import data.contour.http.client
import data.contour.http.client.url
import data.contour.http.expect

Response := client.Get({
  "url": url.http("/unlimited"),
  "headers": {
    "Host": "routeratelimit.projectcontour.io",
    "User-Agent": client.ua("global-rate-limit"),
  },
})

check_for_status_code [msg] {
  msg := expect.response_status_is(Response, 200)
}
